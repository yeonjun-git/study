{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "# K 폴드\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "df_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "print(features.shape[0]) # 전체 feature row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.9667, 0.8667, 0.9333, 0.7333]\n",
      "0.9\n",
      "0.9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_iter = 0\n",
    "cv_accuracy = [] # accuracy의 값을 append 하는 list. 이후 kfold accuracy의 평균을 구하는데 사용 됨\n",
    "for train_index, test_index in kfold.split(features):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "\n",
    "    df_clf.fit(X_train, y_train)\n",
    "    pred = df_clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "print(cv_accuracy)\n",
    "print(np.mean(cv_accuracy))\n",
    "print((sum(cv_accuracy))/n_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "[0.7333, 0.7333, 0.7333]\n",
      "0.7333\n",
      "0.7333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "\n",
    "n_iter = 0\n",
    "cv_accuracy = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(features, label):\n",
    "    X_train, X_test = features[train_index], features[test_index]\n",
    "    y_train, y_test = label[train_index], label[test_index]\n",
    "\n",
    "    \n",
    "    print(y_test)\n",
    "\n",
    "    df_clf.fit(X_train, y_train)\n",
    "    pred = df_clf.predict(X_test)\n",
    "    n_iter += 1\n",
    "\n",
    "    accuracy = np.round(accuracy_score(y_test, pred), 4)\n",
    "    train_size = X_train.shape[0]\n",
    "    test_size = X_test.shape[0]\n",
    "\n",
    "    cv_accuracy.append(accuracy)\n",
    "\n",
    "\n",
    "print(np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified K-fold score: [0.98 0.94 0.98]\n",
      "Average of Score: 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier as dtc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "iris_data = load_iris()\n",
    "dt_clf = dtc(random_state=156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "# cross_val_score: train과 valid 분할 후 scoring // kfold는 stratified로 자동 진행된다.\n",
    "scores = cross_val_score(dt_clf, X=data, y=label, scoring='accuracy', cv=3)\n",
    "\"\"\"\n",
    "적용할 분류기: dt_clf\n",
    "feature: X = data\n",
    "target: y = label\n",
    "나타내고싶은 점수: scoring = 'accuracy' (recall 등도 가능)\n",
    "kfold 횟수: cv = 3\n",
    "\n",
    "\"\"\"\n",
    "print(\"Stratified K-fold score:\", scores)\n",
    "print(\"Average of Score:\", np.round(np.mean(scores),4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV as gscv, train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data.data, iris_data.target, test_size=0.2, random_state=121)\n",
    "\n",
    "dtree = dtc()\n",
    "\n",
    "parameters = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_dtree = gscv(dtree, param_grid=parameters, cv=3, refit=True, return_train_score=True)\n",
    "\"\"\"\n",
    "GridSearchCV: 해당 모델에 적합할 최적의 파라미터를 찾아준다.\n",
    " - grid_dtree는 dtree(의사결정트리분류기)에 최적 파라미터를 찾아낸 모델을 정의하는 것.\n",
    "\n",
    "최적의 파라미터 찾을 모델(분류기): dtree -> DecisionTreeClassifier\n",
    "시도해보는 parameter 조합: param_grid = parameters\n",
    "kfold 분할 테스트 횟수: cv = 3\n",
    "최적의 파라미터를 찾았을 때 모델에 학습 시키기: refit = True\n",
    "\"\"\"\n",
    "\n",
    "grid_dtree.fit(X_train, y_train)\n",
    "\"\"\"\n",
    "gird_dtree는 최적 파라미터를 찾는 인스턴스로 정의된거지만, refit=True를 줌으로써 학습된 estimator로 작동할 수 있게 된다.\n",
    "grid_dtree에 fit으로 train data를 학습시키면, 최적의 파라미터를 찾아 모델링된다.\n",
    "만약, gscv의 refit을 False로 했다면, gird_dtree.fit은 최적의 하이퍼파라미터만 찾아주고\n",
    "이걸 다시 DecisionTreeClassifier에 파라미터로 지정해 모델을 학습시켜 사용해야한다.\n",
    "\"\"\"\n",
    "\n",
    "scores_df = pd.DataFrame(grid_dtree.cv_results_)\n",
    "scores_df\n",
    "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "pred = grid_dtree.predict(X_test)\n",
    "\"\"\"\n",
    "grid_dtree는 하이퍼파라미터를 찾는 인스턴스였지만, refit=True를 통해 estimator를 상속받았기때문에 fit을 통해 학습된 모델로 작동한다.\n",
    "따라서 모델에서 사용하는 predict를 할 수 있다.\n",
    "\"\"\"\n",
    "print(accuracy_score(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
